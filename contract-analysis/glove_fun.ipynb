{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with CALC and pre-trained GloVe word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to make CALC searchable by leveraging pre-trained [GloVe](https://nlp.stanford.edu/projects/glove/) word embeddings.\n",
    "\n",
    "Note that unlike other notebooks in this repository, this one requires Anaconda and runs on Python 3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = pd.read_csv('../data/hourly_prices.csv', index_col=False, thousands=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this cell, you'll need to manually download [glove.6B.zip](http://nlp.stanford.edu/data/glove.6B.zip) and extract it into the `data` directory of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIMS = 50\n",
    "\n",
    "GLOVE_FILE = Path(\".\") / \"..\" / \"data\" / f\"glove.6B.{DIMS}d.txt\"\n",
    "\n",
    "MAX_VOCAB = 400_000\n",
    "\n",
    "words_to_indices = {}\n",
    "indices_to_words = {}\n",
    "\n",
    "# It's probably easier to allocate a matrix that's too big\n",
    "# and then reshape it if we under-filled it, than it is to\n",
    "# constantly make it bigger on each iteration. Though there\n",
    "# might be an easier way to do this that I don't know about.\n",
    "vocab = np.zeros(shape=(MAX_VOCAB, DIMS), dtype=np.float32)\n",
    "\n",
    "for i, line in zip(range(MAX_VOCAB), GLOVE_FILE.open(encoding='utf-8')):\n",
    "    parts = line.split(' ')\n",
    "    word = parts[0]\n",
    "    vocab[i] = np.array(list(map(float, parts[1:])))\n",
    "    words_to_indices[word] = i\n",
    "    indices_to_words[i] = word\n",
    "\n",
    "# Now make the matrix smaller if we under-filled it.\n",
    "if vocab.shape[0] > i + 1:\n",
    "    vocab = vocab[:i + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labor categories into vectors\n",
    "\n",
    "To do this, we'll just average the vectors for all the words in a labor category. It's pretty simple but many sources say it actually works pretty well; it also (hopefully) helps that labor categories are fairly short and word ordering doesn't tend to matter much in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGNORE_WORDS = set(\n",
    "    'i',   # We don't want to confuse the roman numeral \"I\" with the first-person pronoun\n",
    ")\n",
    "\n",
    "SPECIAL_CHARS = re.compile(r'[^A-Za-z]')\n",
    "\n",
    "WHITESPACE = re.compile(r'\\W+')\n",
    "\n",
    "def normalize_labor_category(name):\n",
    "    return WHITESPACE.sub(' ', SPECIAL_CHARS.sub(' ', name.lower())).strip()\n",
    "\n",
    "def labor_category_to_vector(name):\n",
    "    words = [\n",
    "        word for word in normalize_labor_category(name).split()\n",
    "        if word not in IGNORE_WORDS and word in words_to_indices\n",
    "    ]\n",
    "    vector = np.zeros(shape=(1, DIMS), dtype=np.float32)\n",
    "    if len(words) > 0:\n",
    "        for word in words:\n",
    "            vector[0] += vocab[words_to_indices[word]]\n",
    "        vector = vector / len(words)\n",
    "    return vector\n",
    "\n",
    "# Quick sanity check\n",
    "assert normalize_labor_category('Blarg (flag)-2') == 'blarg flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_labor_categories_to_vectors(labor_categories):\n",
    "    n = len(labor_categories)\n",
    "    result = np.zeros(shape=(n, DIMS), dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        result[i] = labor_category_to_vector(labor_categories[i])\n",
    "    return result\n",
    "\n",
    "labor_categories = map_labor_categories_to_vectors(rows['Labor Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a naive KNN algorithm\n",
    "\n",
    "I've never actually implemented K nearest neighbors before, but here's a naive attempt at one. I should probably just use scikit-learn though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest(name, k=5):\n",
    "    vector = labor_category_to_vector(name)\n",
    "    distances = np.linalg.norm(labor_categories - vector, axis=1)\n",
    "    indices = np.argsort(distances)\n",
    "    return list(rows.iloc[list(indices[:k])]['Labor Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform some searches\n",
    "\n",
    "Now that we have all the infrastructure, let's try doing some searches!\n",
    "\n",
    "How about a search for the word \"tutor\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tutor',\n",
       " 'Tutor ***',\n",
       " 'Engineer - Graduate/Apprentice',\n",
       " 'Principal Instruction Technologist',\n",
       " 'Principal Instruction Technologist- Training']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('tutor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's kind of cool, it found \"instruction technologist\", which _sounds_ tutor-like, even though it doesn't have the word \"tutor\" in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
